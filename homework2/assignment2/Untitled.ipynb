{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from utils.general_utils import logged_loop, get_minibatches\n",
    "from q2_parser_transitions import PartialParse, minibatch_parse\n",
    "\n",
    "P_PREFIX = '<p>:'\n",
    "L_PREFIX = '<l>:'\n",
    "UNK = '<UNK>'\n",
    "NULL = '<NULL>'\n",
    "ROOT = '<ROOT>'\n",
    "\n",
    "class Config(object):\n",
    "    language = 'english'\n",
    "    with_punct = True\n",
    "    unlabeled = True\n",
    "    lowercase = True\n",
    "    use_pos = True\n",
    "    use_dep = True\n",
    "    use_dep = use_dep and (not unlabeled)\n",
    "    data_path = './data'\n",
    "    train_file = 'train.conll'\n",
    "    dev_file = 'dev.conll'\n",
    "    test_file = 'test.conll'\n",
    "    embedding_file = './data/en-cw.txt'\n",
    "\n",
    "def read_conll(in_file, lowercase=False, max_example=None):\n",
    "    examples = []\n",
    "    with open(in_file) as f:\n",
    "        word, pos, head, label = [], [], [], []\n",
    "        for line in f.readlines():\n",
    "            sp=line.strip().split('\\t')\n",
    "            if len(sp) == 10:\n",
    "                if '-' not in sp[0]:\n",
    "                    word.append(sp[1].lower() if lowercase else sp[1])\n",
    "                    pos.append(sp[4])\n",
    "                    head.append(int(sp[6]))\n",
    "                    label.append(sp[7])\n",
    "            elif len(word) > 0:\n",
    "                examples.append({'word':word, 'pos': pos, 'head':head, 'label':label})\n",
    "                word, pos, head, label = [], [], [], []\n",
    "                if(max_example is not None) and (len(examples) == max_example):\n",
    "                    break\n",
    "        if len(word) > 0:\n",
    "            examples.append({'word':word, 'pos': pos, 'head':head, 'label':label})\n",
    "    return examples\n",
    "\n",
    "def build_dict(keys, n_max=None, offset=0):\n",
    "    print offset\n",
    "    count = Counter()\n",
    "    for key in keys:\n",
    "        count[key] += 1\n",
    "    ls = count.most_common() if n_max is None else count.most_common(n_max)\n",
    "    return {w[0]: index+offset for (index, w) in enumerate(ls)}\n",
    "    \n",
    "\n",
    "class Parser(object):\n",
    "    \"\"\"Contains everything needed for transition-based dependency parsing except for the model\"\"\"\n",
    "    \n",
    "    def __init__(self,dataset):\n",
    "        root_labels = list([l for ex in dataset for (h,l) in zip(ex['head'], ex['label']) if h==0])\n",
    "        counter = Counter(root_labels)\n",
    "        if len(counter) > 1:\n",
    "            logging.info('Warning: more than one root label')\n",
    "            logging.info(counter)\n",
    "        self.root_label = counter.most_common()[0][0]\n",
    "\n",
    "        deprel = [self.root_label] + list(set([w for ex in dataset for w in ex['label'] if w !=self.root_label]))\n",
    "        tok2id = {L_PREFIX+l:i for (i,l) in enumerate(deprel)}\n",
    "        tok2id[L_PREFIX + NULL] = self.L_NULL = len(tok2id)\n",
    "        \n",
    "        config = Config()\n",
    "        self.unlabeled = config.unlabeled\n",
    "        self.with_punct = config.with_punct\n",
    "        self.use_pos = config.use_pos\n",
    "        self.use_dep = config.use_dep\n",
    "        self.language = config.language\n",
    "        \n",
    "        if self.unlabeled:\n",
    "            trans = ['L', 'R', 'S']\n",
    "            self.n_deprel = 1\n",
    "        else:\n",
    "            trans = ['L-'+l for l in deprel] + ['R-'+l for l in deprel] + ['S']\n",
    "            self.n_deprel = len(deprel)\n",
    "            \n",
    "        self.n_trans = len(trans)\n",
    "        self.tran2id = {t:i for (i,t) in enumerate(trans)}\n",
    "        self.id2tran = {i:t for (i,t) in enumerate(trans)}\n",
    "        tok2id.update(build_dict([P_PREFIX+w for ex in dataset for w in ex['pos']],offset=len(tok2id)))\n",
    "        tok2id[P_PREFIX + UNK] = self.P_UNK = len(tok2id)\n",
    "        tok2id[P_PREFIX + NULL] = self.P_NULL = len(tok2id)\n",
    "        tok2id[P_PREFIX + ROOT] = self.P_ROOT = len(tok2id)\n",
    "        \n",
    "        tok2id.update(build_dict([w for ex in dataset for w in ex['word']],offset=len(tok2id)))\n",
    "        tok2id[UNK] = self.UNK = len(tok2id)\n",
    "        tok2id[NULL] = self.NULL = len(tok2id)\n",
    "        tok2id[ROOT] = self.ROOT = len(tok2id)\n",
    "        \n",
    "        self.tok2id = tok2id\n",
    "        self.id2tok = {v:k for (k,v) in tok2id.items()}\n",
    "        self.n_features = 18 + (18 if config.use_pos else 0) + (12 if config.use_dep else 0)\n",
    "        print \"number of features: \", self.n_features\n",
    "        self.n_tokens = len(tok2id)\n",
    "    \n",
    "    def vectorize(self, examples):\n",
    "        vec_examples = []\n",
    "        for ex in examples:\n",
    "            word = [self.ROOT] + [self.tok2id[w] if w in self.tok2id else self.UNK for w in ex['word'] ]\n",
    "            pos = [self.P_ROOT] + [self.tok2id[P_PREFIX+w] if P_PREFIX+w in self.tok2id else self.P_UNK for w in ex['pos']]\n",
    "            head = [-1] + ex['head']\n",
    "            label= [-1] +[self.tok2id[L_PREFIX + w] if L_PREFIX + w in self.tok2id else -1 for w in ex['label']]\n",
    "            vec_examples.append({'word': word, 'pos': pos,'head': head, 'label': label})\n",
    "        \n",
    "        return vec_examples\n",
    "    \n",
    "    def get_oracle(self, stack, buf, ex):\n",
    "        if len(stack) < 2:\n",
    "            return self.n_trans - 1\n",
    "        \n",
    "        i0 = stack[-1]\n",
    "        i1 = stack[-2]\n",
    "        h0 = ex['head'][i0]\n",
    "        h1 = ex['head'][i1]\n",
    "        l0 = ex['label'][i0]\n",
    "        l1 = ex['label'][i1]\n",
    "        \n",
    "        if self.unlabeled:\n",
    "            if (i1 > 0) and (h1 == i0):\n",
    "                return 0\n",
    "            elif (i1 >= 0) and (h0 == i1) and(not any([x for x in buf if ex['head'][x] == i0])):\n",
    "                return 1\n",
    "            else:\n",
    "                return None if len(buf) == 0 else 2\n",
    "        else:\n",
    "            if (i1 > 0) and (h1 == i0):\n",
    "                return l1 if (l1 >= 0) and (l1 < self.n_deprel) else None\n",
    "            elif (i1 >= 0) and (h0 == i1) and (not any([x for x in buf if ex['head'][x] == i0])):\n",
    "                return l0 + self.n_deprel if (l0 >= 0) and (l0 < self.n_deprel) else None\n",
    "            else:\n",
    "                return None if len(buf) == 0 else self.n_trans - 1\n",
    "            \n",
    "    def legal_labels(self, stack, buf):\n",
    "        labels = ([1] if len(stack) > 2 else [0]) * self.n_deprel\n",
    "        labels += ([1] if len(stack)>=2 else [0]) * self.n_deprel\n",
    "        labels += [1] if len(buf) > 0 else [0]\n",
    "        return labels\n",
    "    \n",
    "    def extract_features(self, stack, buf, arcs, ex):\n",
    "        if stack[0] == \"ROOT\":\n",
    "            stack[0] = 0\n",
    "        \n",
    "        def get_lc(k):\n",
    "            return sorted([arc[1] for arc in arcs if arc[0]==k and arc[1] < k])\n",
    "        def get_rc(k):\n",
    "            return sorted([arc[1] for arc in arcs if arc[0] == k and arc[1] > k], reverse=True)\n",
    "        \n",
    "        p_features = []\n",
    "        l_features = []\n",
    "        \n",
    "        features = [self.NULL] * (3 - len(stack)) + [ex['word'][x] for x in stack[-3:]]\n",
    "        print \"feature step1 --->\",\n",
    "        print features\n",
    "        features += [ex['word'][x] for x in buf[:3]] + [self.NULL] * (3 - len(buf))\n",
    "        print \"feature step2 --->\",\n",
    "        print features\n",
    "        \n",
    "        if self.use_pos:\n",
    "            p_features = [self.P_NULL] * (3 - len(stack)) + [ex['pos'][x] for x in stack[-3:]]\n",
    "            print \"p_feature step1 --->\",\n",
    "            print p_features\n",
    "            p_features += [ex['pos'][x] for x in buf[:3]] + [self.P_NULL] * (3 - len(buf))\n",
    "            print \"p_feature step2 --->\",\n",
    "            print p_features\n",
    "        \n",
    "        for i in xrange(2):\n",
    "            if i < len(stack):\n",
    "                print \"case --- 1\"\n",
    "                k = stack[-i-1]\n",
    "                lc = get_lc(k)\n",
    "                print \"lc, step1 ---->\",\n",
    "                print lc\n",
    "                rc = get_rc(k)\n",
    "                print \"rc, step1 ---->\",\n",
    "                print rc\n",
    "                llc = get_lc(lc[0]) if len(lc) > 0 else []\n",
    "                print \"llc, step1 ---->\",\n",
    "                print llc\n",
    "                rrc = get_rc(rc[0]) if len(rc) > 0 else []\n",
    "                print \"rrc, step1 ---->\",\n",
    "                print rrc\n",
    "                \n",
    "                features.append(ex['word'][lc[0]] if len(lc) > 0 else self.NULL)\n",
    "                features.append(ex['word'][rc[0]] if len(rc) > 0 else self.NULL)\n",
    "                features.append(ex['word'][lc[1]] if len(lc) > 1 else self.NULL)\n",
    "                features.append(ex['word'][rc[1]] if len(rc) > 1 else self.NULL)\n",
    "                features.append(ex['word'][llc[0]] if len(llc) > 0 else self.NULL)\n",
    "                features.append(ex['word'][rrc[0]] if len(rrc) > 0 else self.NULL)\n",
    "                \n",
    "                print \"features step3 --->\",\n",
    "                print features\n",
    "                \n",
    "                if self.use_pos:\n",
    "                    p_features.append(ex['pos'][lc[0]] if len(lc) > 0 else self.P_NULL)\n",
    "                    p_features.append(ex['pos'][rc[0]] if len(rc) > 0 else self.P_NULL)\n",
    "                    p_features.append(ex['pos'][lc[1]] if len(lc) > 1 else self.P_NULL)\n",
    "                    p_features.append(ex['pos'][rc[1]] if len(rc) > 1 else self.P_NULL)\n",
    "                    p_features.append(ex['pos'][llc[0]] if len(llc) > 0 else self.P_NULL)\n",
    "                    p_features.append(ex['pos'][rrc[0]] if len(rrc) > 0 else self.P_NULL)                   \n",
    "                \n",
    "                print \"p_features step3 --->\",\n",
    "                print p_features\n",
    "                \n",
    "                if self.use_dep:\n",
    "                    l_features.append(ex['label'][lc[0]] if len(lc) > 0 else self.L_NULL)\n",
    "                    l_features.append(ex['label'][rc[0]] if len(rc) > 0 else self.L_NULL)\n",
    "                    l_features.append(ex['label'][lc[1]] if len(lc) > 1 else self.L_NULL)\n",
    "                    l_features.append(ex['label'][rc[1]] if len(rc) > 1 else self.L_NULL)\n",
    "                    l_features.append(ex['label'][llc[0]] if len(llc) > 0 else self.L_NULL)\n",
    "                    l_features.append(ex['label'][rrc[0]] if len(rrc) > 0 else self.L_NULL)\n",
    "                print \"l_features step1 --->\"\n",
    "                print l_features\n",
    "            else:\n",
    "                print \"case ---- 2\"\n",
    "                features += [self.NULL] * 6\n",
    "                if self.use_pos:\n",
    "                    p_features += [self.P_NULL] * 6\n",
    "                if self.use_dep:\n",
    "                    l_features += [self.L_NULL] * 6\n",
    "        features += p_features + l_features\n",
    "        assert len(features) == self.n_features\n",
    "        print \"final feature\", features\n",
    "        return features\n",
    "                    \n",
    "        \n",
    "    def create_instances(self,examples):\n",
    "        all_instances = []\n",
    "        succ = 0\n",
    "        for id,ex in enumerate(logged_loop(examples)):\n",
    "            n_words = len(ex['word']) -1\n",
    "            print \"number of words: %d\" % n_words\n",
    "            #arcs = {(h,t,label)}\n",
    "            stack = [0]\n",
    "            buf = [i+1 for i in xrange(n_words)]\n",
    "            arcs = []\n",
    "            instances = []\n",
    "            for i in xrange(n_words * 2):\n",
    "                gold_t = self.get_oracle(stack, buf, ex)\n",
    "                print \"gold_t ---> %d\" % gold_t\n",
    "                if gold_t is None:\n",
    "                    break\n",
    "                legal_labels = self.legal_labels(stack, buf)\n",
    "                print \"legal_labels --->\",\n",
    "                print legal_labels\n",
    "                assert legal_labels[gold_t] == 1\n",
    "                instances.append((self.extract_features(stack, buf, arcs, ex),legal_labels, gold_t))\n",
    "                if gold_t == self.n_trans -1:\n",
    "                    stack.append(buf[0])\n",
    "                    buf = buf[1:]\n",
    "                elif gold_t < self.n_deprel:\n",
    "                    arcs.append((stack[-1], stack[-2], gold_t))\n",
    "                    stack = stack[:-2] + [stack[-1]]\n",
    "                else:\n",
    "                    arcs.append((stack[-2], stack[-1], gold_t - self.n_deprel))\n",
    "                    stack = stack[:-1]\n",
    "            else:\n",
    "                succ +=1\n",
    "                all_instances += instances\n",
    "    \n",
    "        return all_instances\n",
    "                          \n",
    "print 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 3.64 seconds\n",
      "building parser... 6\n",
      "12\n",
      "number of features:  36\n",
      "took 0.00 seconds\n",
      "Loading pretrained embedding... took 3.87 seconds\n",
      "Vectorizing data... took 0.00 seconds\n",
      "Preprocessing training data...\n",
      "1/1 [==============================] - 0s\n",
      "number of words: 5\n",
      "gold_t ---> 2\n",
      "legal_labels ---> [0, 0, 1]\n",
      "feature step1 ---> [18, 18, 19]\n",
      "feature step2 ---> [18, 18, 19, 12, 15, 14]\n",
      "p_feature step1 ---> [10, 10, 11]\n",
      "p_feature step2 ---> [10, 10, 11, 6, 6, 7]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 18, 19, 12, 15, 14, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [10, 10, 11, 6, 6, 7, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "case ---- 2\n",
      "final feature [18, 18, 19, 12, 15, 14, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 10, 10, 11, 6, 6, 7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "gold_t ---> 2\n",
      "legal_labels ---> [0, 1, 1]\n",
      "feature step1 ---> [18, 19, 12]\n",
      "feature step2 ---> [18, 19, 12, 15, 14, 16]\n",
      "p_feature step1 ---> [10, 11, 6]\n",
      "p_feature step2 ---> [10, 11, 6, 6, 7, 6]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 19, 12, 15, 14, 16, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [10, 11, 6, 6, 7, 6, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 19, 12, 15, 14, 16, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [10, 11, 6, 6, 7, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "final feature [18, 19, 12, 15, 14, 16, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 10, 11, 6, 6, 7, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "gold_t ---> 0\n",
      "legal_labels ---> [1, 1, 1]\n",
      "feature step1 ---> [19, 12, 15]\n",
      "feature step2 ---> [19, 12, 15, 14, 16, 13]\n",
      "p_feature step1 ---> [11, 6, 6]\n",
      "p_feature step2 ---> [11, 6, 6, 7, 6, 8]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [19, 12, 15, 14, 16, 13, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [11, 6, 6, 7, 6, 8, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [19, 12, 15, 14, 16, 13, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [11, 6, 6, 7, 6, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "final feature [19, 12, 15, 14, 16, 13, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 11, 6, 6, 7, 6, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "gold_t ---> 2\n",
      "legal_labels ---> [0, 1, 1]\n",
      "feature step1 ---> [18, 19, 15]\n",
      "feature step2 ---> [18, 19, 15, 14, 16, 13]\n",
      "p_feature step1 ---> [10, 11, 6]\n",
      "p_feature step2 ---> [10, 11, 6, 7, 6, 8]\n",
      "case --- 1\n",
      "lc, step1 ----> [1]\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 19, 15, 14, 16, 13, 12, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [10, 11, 6, 7, 6, 8, 6, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 19, 15, 14, 16, 13, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [10, 11, 6, 7, 6, 8, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "final feature [18, 19, 15, 14, 16, 13, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 10, 11, 6, 7, 6, 8, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "gold_t ---> 0\n",
      "legal_labels ---> [1, 1, 1]\n",
      "feature step1 ---> [19, 15, 14]\n",
      "feature step2 ---> [19, 15, 14, 16, 13, 18]\n",
      "p_feature step1 ---> [11, 6, 7]\n",
      "p_feature step2 ---> [11, 6, 7, 6, 8, 10]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [19, 15, 14, 16, 13, 18, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [11, 6, 7, 6, 8, 10, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "case --- 1\n",
      "lc, step1 ----> [1]\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [19, 15, 14, 16, 13, 18, 18, 18, 18, 18, 18, 18, 12, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [11, 6, 7, 6, 8, 10, 10, 10, 10, 10, 10, 10, 6, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "final feature [19, 15, 14, 16, 13, 18, 18, 18, 18, 18, 18, 18, 12, 18, 18, 18, 18, 18, 11, 6, 7, 6, 8, 10, 10, 10, 10, 10, 10, 10, 6, 10, 10, 10, 10, 10]\n",
      "gold_t ---> 2\n",
      "legal_labels ---> [0, 1, 1]\n",
      "feature step1 ---> [18, 19, 14]\n",
      "feature step2 ---> [18, 19, 14, 16, 13, 18]\n",
      "p_feature step1 ---> [10, 11, 7]\n",
      "p_feature step2 ---> [10, 11, 7, 6, 8, 10]\n",
      "case --- 1\n",
      "lc, step1 ----> [2]\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> [1]\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 19, 14, 16, 13, 18, 15, 18, 18, 18, 12, 18]\n",
      "p_features step3 ---> [10, 11, 7, 6, 8, 10, 6, 10, 10, 10, 6, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 19, 14, 16, 13, 18, 15, 18, 18, 18, 12, 18, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [10, 11, 7, 6, 8, 10, 6, 10, 10, 10, 6, 10, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "final feature [18, 19, 14, 16, 13, 18, 15, 18, 18, 18, 12, 18, 18, 18, 18, 18, 18, 18, 10, 11, 7, 6, 8, 10, 6, 10, 10, 10, 6, 10, 10, 10, 10, 10, 10, 10]\n",
      "gold_t ---> 1\n",
      "legal_labels ---> [1, 1, 1]\n",
      "feature step1 ---> [19, 14, 16]\n",
      "feature step2 ---> [19, 14, 16, 13, 18, 18]\n",
      "p_feature step1 ---> [11, 7, 6]\n",
      "p_feature step2 ---> [11, 7, 6, 8, 10, 10]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [19, 14, 16, 13, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [11, 7, 6, 8, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "case --- 1\n",
      "lc, step1 ----> [2]\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> [1]\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [19, 14, 16, 13, 18, 18, 18, 18, 18, 18, 18, 18, 15, 18, 18, 18, 12, 18]\n",
      "p_features step3 ---> [11, 7, 6, 8, 10, 10, 10, 10, 10, 10, 10, 10, 6, 10, 10, 10, 6, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "final feature [19, 14, 16, 13, 18, 18, 18, 18, 18, 18, 18, 18, 15, 18, 18, 18, 12, 18, 11, 7, 6, 8, 10, 10, 10, 10, 10, 10, 10, 10, 6, 10, 10, 10, 6, 10]\n",
      "gold_t ---> 2\n",
      "legal_labels ---> [0, 1, 1]\n",
      "feature step1 ---> [18, 19, 14]\n",
      "feature step2 ---> [18, 19, 14, 13, 18, 18]\n",
      "p_feature step1 ---> [10, 11, 7]\n",
      "p_feature step2 ---> [10, 11, 7, 8, 10, 10]\n",
      "case --- 1\n",
      "lc, step1 ----> [2]\n",
      "rc, step1 ----> [4]\n",
      "llc, step1 ----> [1]\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 19, 14, 13, 18, 18, 15, 16, 18, 18, 12, 18]\n",
      "p_features step3 ---> [10, 11, 7, 8, 10, 10, 6, 6, 10, 10, 6, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 19, 14, 13, 18, 18, 15, 16, 18, 18, 12, 18, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [10, 11, 7, 8, 10, 10, 6, 6, 10, 10, 6, 10, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "final feature [18, 19, 14, 13, 18, 18, 15, 16, 18, 18, 12, 18, 18, 18, 18, 18, 18, 18, 10, 11, 7, 8, 10, 10, 6, 6, 10, 10, 6, 10, 10, 10, 10, 10, 10, 10]\n",
      "gold_t ---> 1\n",
      "legal_labels ---> [1, 1, 0]\n",
      "feature step1 ---> [19, 14, 13]\n",
      "feature step2 ---> [19, 14, 13, 18, 18, 18]\n",
      "p_feature step1 ---> [11, 7, 8]\n",
      "p_feature step2 ---> [11, 7, 8, 10, 10, 10]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [19, 14, 13, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [11, 7, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "case --- 1\n",
      "lc, step1 ----> [2]\n",
      "rc, step1 ----> [4]\n",
      "llc, step1 ----> [1]\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [19, 14, 13, 18, 18, 18, 18, 18, 18, 18, 18, 18, 15, 16, 18, 18, 12, 18]\n",
      "p_features step3 ---> [11, 7, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 6, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "final feature [19, 14, 13, 18, 18, 18, 18, 18, 18, 18, 18, 18, 15, 16, 18, 18, 12, 18, 11, 7, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 10, 10, 6, 10]\n",
      "gold_t ---> 1\n",
      "legal_labels ---> [0, 1, 0]\n",
      "feature step1 ---> [18, 19, 14]\n",
      "feature step2 ---> [18, 19, 14, 18, 18, 18]\n",
      "p_feature step1 ---> [10, 11, 7]\n",
      "p_feature step2 ---> [10, 11, 7, 10, 10, 10]\n",
      "case --- 1\n",
      "lc, step1 ----> [2]\n",
      "rc, step1 ----> [5, 4]\n",
      "llc, step1 ----> [1]\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 19, 14, 18, 18, 18, 15, 13, 18, 16, 12, 18]\n",
      "p_features step3 ---> [10, 11, 7, 10, 10, 10, 6, 8, 10, 6, 6, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "case --- 1\n",
      "lc, step1 ----> []\n",
      "rc, step1 ----> []\n",
      "llc, step1 ----> []\n",
      "rrc, step1 ----> []\n",
      "features step3 ---> [18, 19, 14, 18, 18, 18, 15, 13, 18, 16, 12, 18, 18, 18, 18, 18, 18, 18]\n",
      "p_features step3 ---> [10, 11, 7, 10, 10, 10, 6, 8, 10, 6, 6, 10, 10, 10, 10, 10, 10, 10]\n",
      "l_features step1 --->\n",
      "[]\n",
      "final feature [18, 19, 14, 18, 18, 18, 15, 13, 18, 16, 12, 18, 18, 18, 18, 18, 18, 18, 10, 11, 7, 10, 10, 10, 6, 8, 10, 6, 6, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "reduced = True\n",
    "config=Config()\n",
    "start = time.time()\n",
    "train_set = read_conll(os.path.join(config.data_path, config.train_file),lowercase=config.lowercase)\n",
    "#dev_set=read_conll(os.path.join(config.data_path, config.dev_file), lowercase=config.lowercase)\n",
    "#test_set=read_conll(os.path.join(config.data_path, config.test_file), lowercase=config.lowercase)\n",
    "\n",
    "if reduced:\n",
    "    train_set=train_set[1:2]\n",
    "#    dev_set=dev_set[:500]\n",
    "#    test_set=test_set[:500]\n",
    "'''\n",
    "example \n",
    "the first example in train_set:\n",
    "{'head': [5, 5, 5, 5, 45, 9, 9, 9, 5, 9, 15, 15, 12, 15, 9, 20, 20, 19, 20, 5, 22, 20, 25, 25, 20, 20, 20, 20, 28, 28, 20, 45, 34, 45, 36, 34, 34, 34, 41, 41, 38, 34, 45, 45, 0, 48, 48, 45, 45], \n",
    "'word': ['in', 'an', 'oct.', '19', 'review', 'of', '``', 'the', 'misanthrope', \"''\", 'at', 'chicago', \"'s\", 'goodman', 'theatre', '-lrb-', '``', 'revitalized', 'classics', 'take', 'the', 'stage', 'in', 'windy', 'city', ',', \"''\", 'leisure', '&', 'arts', '-rrb-', ',', 'the', 'role', 'of', 'celimene', ',', 'played', 'by', 'kim', 'cattrall', ',', 'was', 'mistakenly', 'attributed', 'to', 'christina', 'haag', '.'], \n",
    "'pos': ['IN', 'DT', 'NNP', 'CD', 'NN', 'IN', '``', 'DT', 'NN', \"''\", 'IN', 'NNP', 'POS', 'NNP', 'NNP', '-LRB-', '``', 'VBN', 'NNS', 'VB', 'DT', 'NN', 'IN', 'NNP', 'NNP', ',', \"''\", 'NN', 'CC', 'NNS', '-RRB-', ',', 'DT', 'NN', 'IN', 'NNP', ',', 'VBN', 'IN', 'NNP', 'NNP', ',', 'VBD', 'RB', 'VBN', 'TO', 'NNP', 'NNP', '.'], \n",
    "'label': ['case', 'det', 'compound', 'nummod', 'nmod', 'case', 'punct', 'det', 'nmod', 'punct', 'case', 'nmod:poss', 'case', 'compound', 'nmod', 'punct', 'punct', 'amod', 'nsubj', 'dep', 'det', 'dobj', 'case', 'compound', 'nmod', 'punct', 'punct', 'dep', 'cc', 'conj', 'punct', 'punct', 'det', 'nsubjpass', 'case', 'nmod', 'punct', 'acl', 'case', 'compound', 'nmod', 'punct', 'auxpass', 'advmod', 'root', 'case', 'compound', 'nmod', 'punct']}\n",
    "'''\n",
    "print \"took {:.2f} seconds\".format(time.time()-start)\n",
    "\n",
    "print \"building parser...\",\n",
    "start=time.time()\n",
    "parser=Parser(train_set)\n",
    "print \"took {:.2f} seconds\".format(time.time()-start)\n",
    "\n",
    "print \"Loading pretrained embedding...\",\n",
    "start = time.time()\n",
    "word_vectors = {}\n",
    "for line in open(config.embedding_file).readlines():\n",
    "    sp = line.strip().split()\n",
    "    word_vectors[sp[0]] = [float(x) for x in sp[1:]]\n",
    "embeddings_matrix = np.asarray(np.random.normal(0,0.9,(parser.n_tokens,50)),dtype='float32')\n",
    "\n",
    "for token in parser.tok2id:\n",
    "    i = parser.tok2id[token]\n",
    "    if token in word_vectors:\n",
    "        embeddings_matrix[i] = word_vectors[token]\n",
    "    elif token.lower() in word_vectors:\n",
    "        embeddings_matrix[i] = word_vectors[token.lower()]\n",
    "\n",
    "print \"took {:.2f} seconds\".format(time.time() - start)   \n",
    "\n",
    "print \"Vectorizing data...\",\n",
    "start = time.time()\n",
    "train_set = parser.vectorize(train_set)\n",
    "#dev_set = parser.vectorize(dev_set)\n",
    "#test_set = parser.vectorize(test_set)\n",
    "print \"took {:.2f} seconds\".format(time.time() - start)\n",
    "\n",
    "'''\n",
    "the first example become\n",
    "{'head': [-1, 5, 5, 5, 5, 45, 9, 9, 9, 5, 9, 15, 15, 12, 15, 9, 20, 20, 19, 20, 5, 22, 20, 25, 25, 20, 20, 20, 20, 28, 28, 20, 45, 34, 45, 36, 34, 34, 34, 41, 41, 38, 34, 45, 45, 0, 48, 48, 45, 45], \n",
    "'word': [5156, 91, 113, 948, 600, 708, 88, 96, 85, 3417, 97, 109, 1285, 93, 3592, 3245, 145, 96, 4873, 4311, 375, 85, 5042, 91, 4401, 1625, 86, 97, 2553, 201, 3382, 144, 86, 85, 846, 88, 3152, 86, 836, 105, 2690, 3396, 86, 103, 1793, 1673, 89, 3510, 1729, 87], \n",
    "'pos': [84, 40, 41, 42, 49, 39, 40, 61, 41, 39, 62, 40, 42, 60, 42, 42, 71, 61, 53, 44, 50, 41, 39, 40, 42, 42, 45, 62, 39, 51, 44, 72, 45, 41, 39, 40, 42, 45, 53, 40, 42, 42, 45, 48, 47, 53, 52, 42, 42, 46], \n",
    "'label': [-1, 27, 31, 24, 21, 32, 27, 23, 31, 32, 23, 27, 26, 27, 24, 32, 23, 23, 33, 19, 29, 31, 9, 27, 24, 32, 23, 23, 29, 1, 8, 23, 23, 31, 6, 27, 32, 23, 37, 27, 24, 32, 23, 13, 22, 0, 27, 24, 32, 23]}\n",
    "'''\n",
    "print \"Preprocessing training data...\"\n",
    "train_examples = parser.create_instances(train_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
