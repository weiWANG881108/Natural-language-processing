{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import StringIO\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "import numpy as np\n",
    "from numpy import array, zeros, allclose\n",
    "\n",
    "FDIM = 4\n",
    "P_CASE = \"CASE:\"\n",
    "CASES = [\"aa\", \"AA\", \"Aa\", \"aA\"]\n",
    "START_TOKEN = \"<s>\"\n",
    "END_TOKEN = \"</s>\"\n",
    "UNK = \"UUUNKKK\"\n",
    "NUM = \"NNNUMMM\"\n",
    "LBLS = [\n",
    "    \"PER\",\n",
    "    \"ORG\",\n",
    "    \"LOC\",\n",
    "    \"MISC\",\n",
    "    \"O\",\n",
    "    ]\n",
    "\n",
    "class Config:\n",
    "    n_word_features = 2\n",
    "    window_size = 1\n",
    "    n_window_feature = 0\n",
    "    \n",
    "    n_classes = 5\n",
    "    dropout = 0.5\n",
    "    embed_size = 50\n",
    "    hidden_size = 200\n",
    "    batch_size = 2048\n",
    "    n_epochs = 10\n",
    "    lr = 0.001\n",
    "    \n",
    "    def __init__(self, output_path=None):\n",
    "        if output_path:\n",
    "            self.output_path = output_path\n",
    "        else:\n",
    "            self.output_path = \"results/window/{:%Y%m%d_%H%M%S}/\".format(datetime.now())\n",
    "        \n",
    "        self.model_output = self.output_path + \"model.weights\"\n",
    "        self.eval_output = self.output_path + \"results.txt\"\n",
    "        self.log_output = self.output_path + \"log\"\n",
    "        self.conll_output = self.output_path + \"window_predictions.conll\"\n",
    "\n",
    "\n",
    "def casing(word):\n",
    "    if len(word) == 0: return word\n",
    "    if word.islower(): return \"aa\"\n",
    "    elif word.isupper(): return \"AA\"\n",
    "    elif word[0].isupper(): return \"Aa\"\n",
    "    else: return \"aA\"\n",
    "def normalize(word):\n",
    "    \"\"\"\n",
    "    Normalize words that are numbers or have casing\n",
    "    \"\"\"\n",
    "    if word.isdigit(): return NUM\n",
    "    else: return word.lower()\n",
    "\n",
    "def build_dict(words, max_words=None, offset=0):\n",
    "    cnt = Counter(words)\n",
    "    if max_words:\n",
    "        words = cnt.most_common(max_words)\n",
    "    else:\n",
    "        words = cnt.most_common()\n",
    "    \n",
    "    return {word: offset+i for i, (word, _) in enumerate(words)}\n",
    "    \n",
    "class ModelHelper(object):\n",
    "    def __init__(self, tok2id, max_length):\n",
    "        self.tok2id = tok2id\n",
    "        self.START = [tok2id[START_TOKEN], tok2id[P_CASE + \"aa\"]]\n",
    "        self.END = [tok2id[END_TOKEN], tok2id[P_CASE + \"aa\"]]\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    @classmethod\n",
    "    def build(cls, data):\n",
    "        tok2id = build_dict((normalize(word) for sentence, _ in data for word in sentence), offset=1, max_words=10000)\n",
    "        tok2id.update(build_dict([P_CASE + c for c in CASES], offset=len(tok2id)))\n",
    "        #{'CASE:aa': 2, 'CASE:AA': 3, 'CASE:Aa': 4, 'CASE:aA': 5}\n",
    "        tok2id.update(build_dict([START_TOKEN, END_TOKEN, UNK], offset=len(tok2id)))\n",
    "        \n",
    "        max_length = max(len(sentence) for sentence, _ in data)\n",
    "        \n",
    "        return cls(tok2id, max_length)\n",
    "    \n",
    "    def vectorize_example(self, sentence, labels=None):\n",
    "        sentence_ = [[self.tok2id.get(normalize(word), self.tok2id[UNK]), self.tok2id[P_CASE + casing(word)]] for word in sentence]\n",
    "        if labels:\n",
    "            labels_ = [LBLS.index(l) for l in labels]\n",
    "            return sentence_, labels_\n",
    "        else:\n",
    "            return sentence_, [LBLS[-1] for _ in sentence]\n",
    "    \n",
    "    def vectorize(self, data):\n",
    "        return [self.vectorize_example(sentence, labels) for sentence, labels in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(fstream):\n",
    "    \"\"\"\n",
    "    Reads a input stream @fstream (e.g. output of `open(fname, 'r')`) in CoNLL file format.\n",
    "    @returns a list of examples [(tokens), (labels)]. @tokens and @labels are lists of string.\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "    current_toks, current_lbls = [], []\n",
    "    for line in fstream:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0 or line.startswith(\"-DOCSTART-\"):\n",
    "            if len(current_toks) > 0:\n",
    "                assert len(current_toks) == len(current_lbls)\n",
    "                ret.append((current_toks, current_lbls))\n",
    "            current_toks, current_lbls = [], []\n",
    "        else:\n",
    "            tok, lbl = line.split(\"\\t\")\n",
    "            current_toks.append(tok)\n",
    "            current_lbls.append(lbl)\n",
    "    if len(current_toks) > 0:\n",
    "        assert len(current_toks) == len(current_lbls)\n",
    "        ret.append((current_toks, current_lbls))\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], ['ORG', 'O', 'MISC', 'O', 'O', 'O', 'MISC', 'O', 'O']), (['Peter', 'Blackburn'], ['PER', 'PER']), (['BRUSSELS', '1996-08-22'], ['LOC', 'O']), (['The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 'shun', 'British', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.'], ['O', 'ORG', 'ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'MISC', 'O', 'O', 'O', 'O', 'O', 'MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.'], ['LOC', 'O', 'O', 'O', 'O', 'ORG', 'ORG', 'O', 'O', 'O', 'PER', 'PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])]\n",
      "{'CASE:aA': 56, 'CASE:AA': 57, '1996-08-22': 14, 'committee': 15, 'be': 38, 'german': 4, 'it': 16, 'boycott': 17, 'britain': 18, 'werner': 19, 'determine': 20, 'UUUNKKK': 62, 'eu': 21, 'peter': 22, '</s>': 61, 'lamb': 5, 'disagreed': 24, 'said': 6, 'from': 25, 'sheepmeat': 26, 'consumers': 7, 'rejects': 27, 'union': 28, 'veterinary': 29, 'thursday': 30, '.': 2, 'zwingmann': 31, 'to': 1, 'other': 33, 'call': 34, 'scientists': 35, 'was': 36, 'until': 8, 'european': 9, 'CASE:aa': 59, 'sheep': 23, 'buy': 39, \"'s\": 10, 'scientific': 37, 'advice': 11, 'clearer': 40, 'wednesday': 41, 'germany': 42, 'mad': 43, 'shun': 44, 'brussels': 45, 'with': 46, 'than': 47, 'on': 12, 'disease': 53, 'cow': 48, 'blackburn': 49, 'whether': 50, 'should': 51, 'countries': 52, 'commission': 32, 'british': 13, 'CASE:Aa': 58, '<s>': 60, 'transmitted': 54, 'can': 55, 'the': 3, 'representative': 56}\n",
      "[([[21, 57], [27, 59], [4, 58], [34, 59], [1, 59], [17, 59], [13, 58], [5, 59], [2, 56]], [1, 4, 3, 4, 4, 4, 3, 4, 4]), ([[22, 58], [49, 58]], [0, 0]), ([[45, 57], [14, 56]], [2, 4]), ([[3, 58], [9, 58], [32, 58], [6, 59], [12, 59], [30, 58], [16, 59], [24, 59], [46, 59], [4, 58], [11, 59], [1, 59], [7, 59], [1, 59], [44, 59], [13, 58], [5, 59], [8, 59], [35, 59], [20, 59], [50, 59], [43, 59], [48, 59], [53, 59], [55, 59], [38, 59], [54, 59], [1, 59], [23, 59], [2, 56]], [4, 1, 1, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]), ([[42, 58], [10, 59], [56, 59], [1, 59], [3, 59], [9, 58], [28, 58], [10, 59], [29, 59], [15, 59], [19, 58], [31, 58], [6, 59], [12, 59], [41, 58], [7, 59], [51, 59], [39, 59], [26, 59], [25, 59], [52, 59], [33, 59], [47, 59], [18, 58], [8, 59], [3, 59], [37, 59], [11, 59], [36, 59], [40, 59], [2, 56]], [2, 4, 4, 4, 4, 1, 1, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4])]\n"
     ]
    }
   ],
   "source": [
    "data_train = \"./data/tiny.conll\"\n",
    "data_dev = \"./data/tiny.conll\"\n",
    "fstream = open(data_train, \"r\")\n",
    "train = read_conll(fstream)\n",
    "train = train[:5]\n",
    "fstream = open(data_dev, \"r\")\n",
    "dev = read_conll(fstream)\n",
    "print train\n",
    "helper = ModelHelper.build(train)\n",
    "print helper.tok2id\n",
    "train_data_ = helper.vectorize(train)\n",
    "print train_data_\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
